{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "8224d4ec9857f5f2d3915b47613da9acc0e9c91d6b4c8d2fd51c493a871d537c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../api\")\n",
    "import pandas as pd\n",
    "from functions import bertify, fit_score_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/02/emotions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    28369\n",
       "1    17711\n",
       "Name: is_positive, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.is_positive.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "You try to use a model that was created with version 1.2.0, however, your version is 1.1.1. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n",
      "Encoded !\n"
     ]
    }
   ],
   "source": [
    "y = df['feeling']\n",
    "X = bertify(df['lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# model = LogisticRegression(max_iter=1500, multi_class=\"multinomial\", C=100)\n",
    "# model = fit_score_model(model, X, y)"
   ]
  },
  {
   "source": [
    "0.47974879402930737\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       anger       0.53      0.43      0.47       622\n",
    "        fear       0.58      0.50      0.54       551\n",
    "         fun       0.20      0.05      0.08       356\n",
    "       happy       0.54      0.64      0.58      2513\n",
    "        hate       0.31      0.13      0.19       239\n",
    "        love       0.51      0.33      0.40      1160\n",
    "     neutral       0.41      0.49      0.45      1646\n",
    "     sadness       0.51      0.55      0.53      2255\n",
    "       worry       0.38      0.40      0.39      1645\n",
    "\n",
    "    accuracy                           0.48     10987\n",
    "   macro avg       0.44      0.39      0.40     10987\n",
    "weighted avg       0.47      0.48      0.47     10987"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# path = f'../models/cuml_LogisticRegression.joblib'\n",
    "# joblib.dump(model, path, compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVC\n",
    "# model_2 = LinearSVC(max_iter=1500)\n",
    "# model_2 = fit_score_model(model_2, X, y)"
   ]
  },
  {
   "source": [
    "0.482388277054701\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       anger       0.54      0.34      0.42       622\n",
    "        fear       0.58      0.47      0.52       551\n",
    "         fun       0.50      0.01      0.01       356\n",
    "       happy       0.52      0.68      0.59      2513\n",
    "        hate       0.35      0.03      0.05       239\n",
    "        love       0.50      0.29      0.37      1160\n",
    "     neutral       0.42      0.51      0.46      1646\n",
    "     sadness       0.50      0.58      0.54      2255\n",
    "       worry       0.39      0.38      0.39      1645\n",
    "\n",
    "    accuracy                           0.48     10987\n",
    "   macro avg       0.48      0.36      0.37     10987\n",
    "weighted avg       0.48      0.48      0.46     10987"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'anger': 0, 'enthusiasm': 1, 'fear': 2, 'happy': 3, 'hate': 4, 'love': 5, 'neutral': 6, 'relief': 7, 'sadness': 8, 'surprise': 9, 'worry': 10}\n{0: 'anger', 1: 'enthusiasm', 2: 'fear', 3: 'happy', 4: 'hate', 5: 'love', 6: 'neutral', 7: 'relief', 8: 'sadness', 9: 'surprise', 10: 'worry'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from xgboost import XGBClassifier, callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    learning_rate=0.01, \n",
    "    n_estimators=1500,\n",
    "    predictor=\"gpu_predictor\",\n",
    "    tree_method=\"gpu_hist\",\n",
    "    gpu_id=0,\n",
    "    objective='multi:softprob',\n",
    "    min_child_weight=1.5,\n",
    "    subsample=0.8,\n",
    "    sampling_method=\"gradient_based\",\n",
    "    max_depth=20,\n",
    "    gamma=1.5,\n",
    "    colsample_bytree=0.8 \n",
    ")\n",
    "\n",
    "#Extracting different classes\n",
    "class_to_idx = {x:i for i,x in enumerate(sorted(df.sentiment.unique()))}\n",
    "idx_to_class = {i:x for i,x in enumerate(sorted(df.sentiment.unique()))}\n",
    "print(class_to_idx)\n",
    "print(idx_to_class)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, train_size=0.85,\n",
    "                                                    random_state=42)\n",
    "\n",
    "early_stopping_rounds = 20\n",
    "callbacks = [callback.EarlyStopping(rounds=early_stopping_rounds,\n",
    "                                        save_best=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0]\tvalidation_0-merror:0.16381\tvalidation_1-merror:0.57413\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-26125fffd149>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"merror\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    907\u001b[0m             eval_group=None, label_transform=label_transform)\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         self._Booster = train(xgb_options, train_dmatrix,\n\u001b[0m\u001b[1;32m    910\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_boosting_rounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                               \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \"\"\"\n\u001b[0;32m--> 227\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    228\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1281\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb.fit(X_train, y_train, eval_set=[(X_train, y_train),(X_test, y_test)], eval_metric=[\"merror\"], callbacks=callbacks, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot \n",
    "results = xgb.evals_result()\n",
    "epochs = len(results['validation_0']['merror'])\n",
    "x_axis = range(0, epochs)\n",
    "\n",
    "\n",
    "fig, ax = pyplot.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['merror'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['merror'], label='Test')\n",
    "ax.legend()\n",
    "pyplot.ylabel('merror')\n",
    "pyplot.title('XGBoost merror')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "y_pred = xgb.predict(X_test)\n",
    "preds = bst.predict(dtest, ntree_limit=0, training=False)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# folds = 4\n",
    "# param_comb = 40\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "# params = {\n",
    "#         'min_child_weight': [1, 5, 10],\n",
    "#         'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "#         'subsample': [0.6, 0.8, 1.0],\n",
    "#         'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "#         'max_depth': [3, 4, 5]\n",
    "#         }\n",
    "\n",
    "# random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='accuracy', n_jobs=1, cv=skf.split(X,y), verbose=3, random_state=1001 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "[CV 1/4] END colsample_bytree=1.0, gamma=5, max_depth=3, min_child_weight=5, subsample=1.0; total time=  42.0s\n",
      "[CV 2/4] END colsample_bytree=1.0, gamma=5, max_depth=3, min_child_weight=5, subsample=1.0; total time=  42.3s\n",
      "[CV 3/4] END colsample_bytree=1.0, gamma=5, max_depth=3, min_child_weight=5, subsample=1.0; total time=  42.4s\n",
      "[CV 4/4] END colsample_bytree=1.0, gamma=5, max_depth=3, min_child_weight=5, subsample=1.0; total time=  42.5s\n",
      "[CV 1/4] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time= 1.4min\n",
      "[CV 2/4] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time= 1.4min\n",
      "[CV 3/4] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time= 1.4min\n",
      "[CV 4/4] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=1, subsample=0.6; total time= 1.4min\n",
      "[CV 1/4] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.8; total time= 1.4min\n",
      "[CV 2/4] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.8; total time= 1.4min\n",
      "[CV 3/4] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.8; total time= 1.4min\n",
      "[CV 4/4] END colsample_bytree=0.8, gamma=1, max_depth=5, min_child_weight=5, subsample=0.8; total time= 1.4min\n",
      "[CV 1/4] END colsample_bytree=0.6, gamma=5, max_depth=5, min_child_weight=5, subsample=1.0; total time= 1.2min\n",
      "[CV 2/4] END colsample_bytree=0.6, gamma=5, max_depth=5, min_child_weight=5, subsample=1.0; total time= 1.1min\n",
      "[CV 3/4] END colsample_bytree=0.6, gamma=5, max_depth=5, min_child_weight=5, subsample=1.0; total time= 1.1min\n",
      "[CV 4/4] END colsample_bytree=0.6, gamma=5, max_depth=5, min_child_weight=5, subsample=1.0; total time= 1.1min\n",
      "[CV 1/4] END colsample_bytree=1.0, gamma=1, max_depth=4, min_child_weight=1, subsample=0.8; total time=  54.6s\n",
      "[CV 2/4] END colsample_bytree=1.0, gamma=1, max_depth=4, min_child_weight=1, subsample=0.8; total time=  54.4s\n",
      "[CV 3/4] END colsample_bytree=1.0, gamma=1, max_depth=4, min_child_weight=1, subsample=0.8; total time=  54.5s\n",
      "[CV 4/4] END colsample_bytree=1.0, gamma=1, max_depth=4, min_child_weight=1, subsample=0.8; total time=  54.6s\n",
      "[CV 1/4] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=10, subsample=1.0; total time=  45.5s\n",
      "[CV 2/4] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=10, subsample=1.0; total time=  45.2s\n",
      "[CV 3/4] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=10, subsample=1.0; total time=  45.3s\n",
      "[CV 4/4] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=10, subsample=1.0; total time=  45.2s\n",
      "[CV 1/4] END colsample_bytree=0.6, gamma=5, max_depth=5, min_child_weight=1, subsample=1.0; total time= 1.1min\n",
      "[CV 2/4] END colsample_bytree=0.6, gamma=5, max_depth=5, min_child_weight=1, subsample=1.0; total time= 1.1min\n",
      "[CV 3/4] END colsample_bytree=0.6, gamma=5, max_depth=5, min_child_weight=1, subsample=1.0; total time= 1.1min\n",
      "[CV 4/4] END colsample_bytree=0.6, gamma=5, max_depth=5, min_child_weight=1, subsample=1.0; total time= 1.1min\n",
      "[CV 1/4] END colsample_bytree=0.8, gamma=2, max_depth=3, min_child_weight=1, subsample=0.8; total time=  33.6s\n",
      "[CV 2/4] END colsample_bytree=0.8, gamma=2, max_depth=3, min_child_weight=1, subsample=0.8; total time=  33.6s\n",
      "[CV 3/4] END colsample_bytree=0.8, gamma=2, max_depth=3, min_child_weight=1, subsample=0.8; total time=  33.7s\n",
      "[CV 4/4] END colsample_bytree=0.8, gamma=2, max_depth=3, min_child_weight=1, subsample=0.8; total time=  33.7s\n",
      "[CV 1/4] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.8; total time= 1.1min\n",
      "[CV 2/4] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.8; total time= 1.1min\n",
      "[CV 3/4] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.8; total time= 1.1min\n",
      "[CV 4/4] END colsample_bytree=0.6, gamma=0.5, max_depth=5, min_child_weight=1, subsample=0.8; total time= 1.1min\n",
      "[CV 1/4] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.8; total time=  44.5s\n",
      "[CV 2/4] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.8; total time=  44.4s\n",
      "[CV 3/4] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.8; total time=  44.5s\n",
      "[CV 4/4] END colsample_bytree=0.6, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.8; total time=  44.5s\n",
      "[CV 1/4] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=  50.1s\n",
      "[CV 2/4] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=  49.9s\n",
      "[CV 3/4] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=  50.1s\n",
      "[CV 4/4] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=  50.1s\n",
      "[CV 1/4] END colsample_bytree=1.0, gamma=1.5, max_depth=3, min_child_weight=10, subsample=1.0; total time=  36.8s\n",
      "[CV 2/4] END colsample_bytree=1.0, gamma=1.5, max_depth=3, min_child_weight=10, subsample=1.0; total time=  37.0s\n",
      "[CV 3/4] END colsample_bytree=1.0, gamma=1.5, max_depth=3, min_child_weight=10, subsample=1.0; total time=  37.1s\n",
      "[CV 4/4] END colsample_bytree=1.0, gamma=1.5, max_depth=3, min_child_weight=10, subsample=1.0; total time=  36.9s\n",
      "[CV 1/4] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=10, subsample=0.6; total time= 1.1min\n",
      "[CV 2/4] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=10, subsample=0.6; total time= 1.1min\n",
      "[CV 3/4] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=10, subsample=0.6; total time= 1.1min\n",
      "[CV 4/4] END colsample_bytree=0.6, gamma=1, max_depth=5, min_child_weight=10, subsample=0.6; total time= 1.1min\n",
      "[CV 1/4] END colsample_bytree=1.0, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time= 1.4min\n",
      "[CV 2/4] END colsample_bytree=1.0, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time= 1.4min\n",
      "[CV 3/4] END colsample_bytree=1.0, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time= 1.4min\n",
      "[CV 4/4] END colsample_bytree=1.0, gamma=0.5, max_depth=5, min_child_weight=5, subsample=1.0; total time= 1.4min\n",
      "[CV 1/4] END colsample_bytree=1.0, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time= 1.4min\n",
      "[CV 2/4] END colsample_bytree=1.0, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time= 1.4min\n",
      "[CV 3/4] END colsample_bytree=1.0, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time= 1.4min\n",
      "[CV 4/4] END colsample_bytree=1.0, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time= 1.5min\n",
      "[CV 1/4] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=10, subsample=0.8; total time=  49.4s\n",
      "[CV 2/4] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=10, subsample=0.8; total time=  49.2s\n",
      "[CV 3/4] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=10, subsample=0.8; total time=  49.1s\n",
      "[CV 4/4] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=10, subsample=0.8; total time=  49.3s\n",
      "[CV 1/4] END colsample_bytree=1.0, gamma=1, max_depth=4, min_child_weight=10, subsample=1.0; total time=  55.3s\n",
      "[CV 2/4] END colsample_bytree=1.0, gamma=1, max_depth=4, min_child_weight=10, subsample=1.0; total time=  55.2s\n",
      "[CV 3/4] END colsample_bytree=1.0, gamma=1, max_depth=4, min_child_weight=10, subsample=1.0; total time=  55.3s\n",
      "[CV 4/4] END colsample_bytree=1.0, gamma=1, max_depth=4, min_child_weight=10, subsample=1.0; total time=  55.4s\n",
      "[CV 1/4] END colsample_bytree=1.0, gamma=1.5, max_depth=4, min_child_weight=10, subsample=0.8; total time=  54.6s\n",
      "[CV 2/4] END colsample_bytree=1.0, gamma=1.5, max_depth=4, min_child_weight=10, subsample=0.8; total time=  54.3s\n",
      "[CV 3/4] END colsample_bytree=1.0, gamma=1.5, max_depth=4, min_child_weight=10, subsample=0.8; total time=  54.4s\n",
      "[CV 4/4] END colsample_bytree=1.0, gamma=1.5, max_depth=4, min_child_weight=10, subsample=0.8; total time=  54.5s\n",
      "[CV 1/4] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=  48.2s\n",
      "[CV 2/4] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=  48.1s\n",
      "[CV 3/4] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=  48.1s\n",
      "[CV 4/4] END colsample_bytree=0.8, gamma=0.5, max_depth=4, min_child_weight=1, subsample=0.6; total time=  48.3s\n",
      "[CV 1/4] END colsample_bytree=0.8, gamma=2, max_depth=5, min_child_weight=1, subsample=0.6; total time= 1.2min\n",
      "[CV 2/4] END colsample_bytree=0.8, gamma=2, max_depth=5, min_child_weight=1, subsample=0.6; total time= 1.2min\n",
      "[CV 3/4] END colsample_bytree=0.8, gamma=2, max_depth=5, min_child_weight=1, subsample=0.6; total time= 1.2min\n",
      "[CV 4/4] END colsample_bytree=0.8, gamma=2, max_depth=5, min_child_weight=1, subsample=0.6; total time= 1.2min\n",
      "[CV 1/4] END colsample_bytree=1.0, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=  55.2s\n",
      "[CV 2/4] END colsample_bytree=1.0, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=  55.2s\n",
      "[CV 3/4] END colsample_bytree=1.0, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=  55.3s\n",
      "[CV 4/4] END colsample_bytree=1.0, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=  55.4s\n",
      "[CV 1/4] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.8; total time=  31.4s\n",
      "[CV 2/4] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.8; total time=  31.4s\n",
      "[CV 3/4] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.8; total time=  31.4s\n",
      "[CV 4/4] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=0.8; total time=  31.5s\n",
      "[CV 1/4] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time= 1.3min\n",
      "[CV 2/4] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time= 1.3min\n",
      "[CV 3/4] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time= 1.3min\n",
      "[CV 4/4] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=1, subsample=1.0; total time= 1.3min\n",
      "[CV 1/4] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=  32.0s\n",
      "[CV 2/4] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=  31.9s\n",
      "[CV 3/4] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=  32.0s\n",
      "[CV 4/4] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=5, subsample=1.0; total time=  32.0s\n",
      "[CV 1/4] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=  30.6s\n",
      "[CV 2/4] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=  30.7s\n",
      "[CV 3/4] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=  30.6s\n",
      "[CV 4/4] END colsample_bytree=0.6, gamma=0.5, max_depth=3, min_child_weight=5, subsample=0.6; total time=  30.6s\n",
      "[CV 1/4] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=10, subsample=0.6; total time= 1.2min\n",
      "[CV 2/4] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=10, subsample=0.6; total time= 1.2min\n",
      "[CV 3/4] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=10, subsample=0.6; total time= 1.2min\n",
      "[CV 4/4] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=10, subsample=0.6; total time= 1.2min\n",
      "[CV 1/4] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=10, subsample=1.0; total time= 1.3min\n",
      "[CV 2/4] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=10, subsample=1.0; total time= 1.3min\n",
      "[CV 3/4] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=10, subsample=1.0; total time= 1.3min\n",
      "[CV 4/4] END colsample_bytree=0.8, gamma=0.5, max_depth=5, min_child_weight=10, subsample=1.0; total time= 1.3min\n",
      "[CV 1/4] END colsample_bytree=0.6, gamma=2, max_depth=5, min_child_weight=5, subsample=0.6; total time= 1.1min\n",
      "[CV 2/4] END colsample_bytree=0.6, gamma=2, max_depth=5, min_child_weight=5, subsample=0.6; total time= 1.1min\n",
      "[CV 3/4] END colsample_bytree=0.6, gamma=2, max_depth=5, min_child_weight=5, subsample=0.6; total time= 1.1min\n",
      "[CV 4/4] END colsample_bytree=0.6, gamma=2, max_depth=5, min_child_weight=5, subsample=0.6; total time= 1.1min\n",
      "[CV 1/4] END colsample_bytree=1.0, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=  55.1s\n",
      "[CV 2/4] END colsample_bytree=1.0, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=  55.1s\n",
      "[CV 3/4] END colsample_bytree=1.0, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=  55.3s\n",
      "[CV 4/4] END colsample_bytree=1.0, gamma=0.5, max_depth=4, min_child_weight=5, subsample=1.0; total time=  55.3s\n",
      "[CV 1/4] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=10, subsample=0.8; total time=  31.4s\n",
      "[CV 2/4] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=10, subsample=0.8; total time=  31.4s\n",
      "[CV 3/4] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=10, subsample=0.8; total time=  31.4s\n",
      "[CV 4/4] END colsample_bytree=0.6, gamma=1, max_depth=3, min_child_weight=10, subsample=0.8; total time=  31.4s\n",
      "[CV 1/4] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=  50.1s\n",
      "[CV 2/4] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=  49.9s\n",
      "[CV 3/4] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=  50.1s\n",
      "[CV 4/4] END colsample_bytree=0.8, gamma=1, max_depth=4, min_child_weight=5, subsample=1.0; total time=  50.1s\n",
      "[CV 1/4] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time= 1.3min\n",
      "[CV 2/4] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time= 1.3min\n",
      "[CV 3/4] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time= 1.3min\n",
      "[CV 4/4] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=5, subsample=1.0; total time= 1.3min\n",
      "[CV 1/4] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=10, subsample=1.0; total time= 1.3min\n",
      "[CV 2/4] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=10, subsample=1.0; total time= 1.3min\n",
      "[CV 3/4] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=10, subsample=1.0; total time= 1.3min\n",
      "[CV 4/4] END colsample_bytree=0.8, gamma=1.5, max_depth=5, min_child_weight=10, subsample=1.0; total time= 1.3min\n",
      "[CV 1/4] END colsample_bytree=1.0, gamma=5, max_depth=5, min_child_weight=5, subsample=1.0; total time= 1.4min\n",
      "[CV 2/4] END colsample_bytree=1.0, gamma=5, max_depth=5, min_child_weight=5, subsample=1.0; total time= 1.4min\n",
      "[CV 3/4] END colsample_bytree=1.0, gamma=5, max_depth=5, min_child_weight=5, subsample=1.0; total time= 1.4min\n",
      "[CV 4/4] END colsample_bytree=1.0, gamma=5, max_depth=5, min_child_weight=5, subsample=1.0; total time= 1.4min\n",
      "[CV 1/4] END colsample_bytree=1.0, gamma=2, max_depth=5, min_child_weight=10, subsample=0.8; total time= 1.4min\n",
      "[CV 2/4] END colsample_bytree=1.0, gamma=2, max_depth=5, min_child_weight=10, subsample=0.8; total time= 1.4min\n",
      "[CV 3/4] END colsample_bytree=1.0, gamma=2, max_depth=5, min_child_weight=10, subsample=0.8; total time= 1.4min\n",
      "[CV 4/4] END colsample_bytree=1.0, gamma=2, max_depth=5, min_child_weight=10, subsample=0.8; total time= 1.4min\n",
      "[CV 1/4] END colsample_bytree=1.0, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time= 1.4min\n",
      "[CV 2/4] END colsample_bytree=1.0, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time= 1.4min\n",
      "[CV 3/4] END colsample_bytree=1.0, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time= 1.4min\n",
      "[CV 4/4] END colsample_bytree=1.0, gamma=1, max_depth=5, min_child_weight=5, subsample=1.0; total time= 1.4min\n",
      "[CV 1/4] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=  32.1s\n",
      "[CV 2/4] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=  31.9s\n",
      "[CV 3/4] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=  32.0s\n",
      "[CV 4/4] END colsample_bytree=0.6, gamma=1.5, max_depth=3, min_child_weight=1, subsample=1.0; total time=  31.9s\n",
      "[CV 1/4] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.8; total time=  49.3s\n",
      "[CV 2/4] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.8; total time=  49.1s\n",
      "[CV 3/4] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.8; total time=  49.2s\n",
      "[CV 4/4] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=0.8; total time=  49.3s\n",
      "[CV 1/4] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=  50.1s\n",
      "[CV 2/4] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=  49.9s\n",
      "[CV 3/4] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=  49.9s\n",
      "[CV 4/4] END colsample_bytree=0.8, gamma=1.5, max_depth=4, min_child_weight=1, subsample=1.0; total time=  50.1s\n",
      "[CV 1/4] END colsample_bytree=1.0, gamma=2, max_depth=5, min_child_weight=10, subsample=1.0; total time= 1.4min\n",
      "[CV 2/4] END colsample_bytree=1.0, gamma=2, max_depth=5, min_child_weight=10, subsample=1.0; total time= 1.4min\n",
      "[CV 3/4] END colsample_bytree=1.0, gamma=2, max_depth=5, min_child_weight=10, subsample=1.0; total time= 1.4min\n",
      "[CV 4/4] END colsample_bytree=1.0, gamma=2, max_depth=5, min_child_weight=10, subsample=1.0; total time= 1.4min\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x7f6990441dd0>,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           eval_metric='merror', gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=0.02,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_chil...\n",
       "                                           random_state=None, reg_alpha=None,\n",
       "                                           reg_lambda=None,\n",
       "                                           scale_pos_weight=None,\n",
       "                                           subsample=None,\n",
       "                                           tree_method='gpu_hist',\n",
       "                                           use_label_encoder=False,\n",
       "                                           validate_parameters=None, ...),\n",
       "                   n_iter=40, n_jobs=1,\n",
       "                   param_distributions={'colsample_bytree': [0.6, 0.8, 1.0],\n",
       "                                        'gamma': [0.5, 1, 1.5, 2, 5],\n",
       "                                        'max_depth': [3, 4, 5],\n",
       "                                        'min_child_weight': [1, 5, 10],\n",
       "                                        'subsample': [0.6, 0.8, 1.0]},\n",
       "                   random_state=1001, scoring='accuracy', verbose=3)"
      ]
     },
     "metadata": {},
     "execution_count": 149
    }
   ],
   "source": [
    "# random_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n All results:\n{'mean_fit_time': array([42.11209416, 85.00206012, 85.93747759, 65.8242327 , 54.27026933,\n       45.03359067, 64.50765902, 33.45770437, 65.46005875, 44.22959161,\n       49.7930373 , 36.73288029, 63.83013451, 86.4965322 , 86.56124043,\n       48.97886789, 55.03147089, 54.20877081, 47.92296022, 73.69206941,\n       55.02010632, 31.24818277, 76.31324762, 31.76625061, 30.43675667,\n       73.27762645, 76.18129599, 63.62187028, 54.93193001, 31.19178474,\n       49.78756261, 76.09491116, 75.86240059, 83.79472476, 84.85177368,\n       86.40079623, 31.76039732, 48.9852407 , 49.74325514, 86.04982704]), 'std_fit_time': array([0.16432383, 0.23746821, 0.07997075, 2.57179164, 0.07448725,\n       0.10300881, 0.17346926, 0.01956169, 0.09782388, 0.05300846,\n       0.06408824, 0.08993655, 0.12225519, 0.09889082, 0.13478865,\n       0.10473419, 0.08173004, 0.09653312, 0.06880713, 0.04655265,\n       0.09731736, 0.02466617, 0.09324099, 0.05588482, 0.03715853,\n       0.11329309, 0.14220961, 0.07096156, 0.1260765 , 0.01003317,\n       0.07162616, 0.09232359, 0.12317711, 0.26205016, 0.03839959,\n       0.03420512, 0.06054005, 0.06204354, 0.0957435 , 0.03932724]), 'mean_score_time': array([0.2041195 , 0.33227724, 0.33307171, 0.3451764 , 0.25044549,\n       0.25253183, 0.34391338, 0.20031148, 0.32745206, 0.25103027,\n       0.25420749, 0.20119715, 0.3231315 , 0.32694161, 0.31999069,\n       0.25559866, 0.25636458, 0.25268954, 0.25513768, 0.32536495,\n       0.25044948, 0.1967423 , 0.32128507, 0.20275432, 0.19906372,\n       0.32975465, 0.32248718, 0.3321411 , 0.25375074, 0.20069015,\n       0.25220525, 0.32467979, 0.32848632, 0.34098822, 0.32845509,\n       0.32303536, 0.2004115 , 0.2545262 , 0.25100821, 0.32378209]), 'std_score_time': array([0.00234883, 0.00227236, 0.00242686, 0.00260944, 0.00153941,\n       0.00355329, 0.00319924, 0.00594115, 0.00669488, 0.00139014,\n       0.00746034, 0.00327018, 0.00415037, 0.007251  , 0.0019247 ,\n       0.00431949, 0.00794581, 0.00480723, 0.00203249, 0.00653582,\n       0.00192699, 0.00284256, 0.00852227, 0.00529068, 0.00384746,\n       0.00379418, 0.00264814, 0.00319155, 0.00616125, 0.00226393,\n       0.00493195, 0.00576081, 0.00705107, 0.00583751, 0.0021325 ,\n       0.01120881, 0.00276891, 0.00426464, 0.00248538, 0.00931894]), 'param_subsample': masked_array(data=[1.0, 0.6, 0.8, 1.0, 0.8, 1.0, 1.0, 0.8, 0.8, 0.8, 1.0,\n                   1.0, 0.6, 1.0, 1.0, 0.8, 1.0, 0.8, 0.6, 0.6, 1.0, 0.8,\n                   1.0, 1.0, 0.6, 0.6, 1.0, 0.6, 1.0, 0.8, 1.0, 1.0, 1.0,\n                   1.0, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0],\n             mask=[False, False, False, False, False, False, False, False,\n                   False, False, False, False, False, False, False, False,\n                   False, False, False, False, False, False, False, False,\n                   False, False, False, False, False, False, False, False,\n                   False, False, False, False, False, False, False, False],\n       fill_value='?',\n            dtype=object), 'param_min_child_weight': masked_array(data=[5, 1, 5, 5, 1, 10, 1, 1, 1, 1, 1, 10, 10, 5, 1, 10, 10,\n                   10, 1, 1, 5, 1, 1, 5, 5, 10, 10, 5, 5, 10, 5, 5, 10, 5,\n                   10, 5, 1, 1, 1, 10],\n             mask=[False, False, False, False, False, False, False, False,\n                   False, False, False, False, False, False, False, False,\n                   False, False, False, False, False, False, False, False,\n                   False, False, False, False, False, False, False, False,\n                   False, False, False, False, False, False, False, False],\n       fill_value='?',\n            dtype=object), 'param_max_depth': masked_array(data=[3, 5, 5, 5, 4, 4, 5, 3, 5, 4, 4, 3, 5, 5, 5, 4, 4, 4,\n                   4, 5, 4, 3, 5, 3, 3, 5, 5, 5, 4, 3, 4, 5, 5, 5, 5, 5,\n                   3, 4, 4, 5],\n             mask=[False, False, False, False, False, False, False, False,\n                   False, False, False, False, False, False, False, False,\n                   False, False, False, False, False, False, False, False,\n                   False, False, False, False, False, False, False, False,\n                   False, False, False, False, False, False, False, False],\n       fill_value='?',\n            dtype=object), 'param_gamma': masked_array(data=[5, 1.5, 1, 5, 1, 1.5, 5, 2, 0.5, 1.5, 0.5, 1.5, 1, 0.5,\n                   0.5, 1.5, 1, 1.5, 0.5, 2, 1, 1.5, 0.5, 1.5, 0.5, 1.5,\n                   0.5, 2, 0.5, 1, 1, 1.5, 1.5, 5, 2, 1, 1.5, 1.5, 1.5, 2],\n             mask=[False, False, False, False, False, False, False, False,\n                   False, False, False, False, False, False, False, False,\n                   False, False, False, False, False, False, False, False,\n                   False, False, False, False, False, False, False, False,\n                   False, False, False, False, False, False, False, False],\n       fill_value='?',\n            dtype=object), 'param_colsample_bytree': masked_array(data=[1.0, 0.8, 0.8, 0.6, 1.0, 0.6, 0.6, 0.8, 0.6, 0.6, 0.8,\n                   1.0, 0.6, 1.0, 1.0, 0.8, 1.0, 1.0, 0.8, 0.8, 1.0, 0.6,\n                   0.8, 0.6, 0.6, 0.8, 0.8, 0.6, 1.0, 0.6, 0.8, 0.8, 0.8,\n                   1.0, 1.0, 1.0, 0.6, 0.8, 0.8, 1.0],\n             mask=[False, False, False, False, False, False, False, False,\n                   False, False, False, False, False, False, False, False,\n                   False, False, False, False, False, False, False, False,\n                   False, False, False, False, False, False, False, False,\n                   False, False, False, False, False, False, False, False],\n       fill_value='?',\n            dtype=object), 'params': [{'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 3, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 5, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 4, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 4, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 5, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 3, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 0.5, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 4, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 4, 'gamma': 0.5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 3, 'gamma': 1.5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 5, 'gamma': 1, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 10, 'max_depth': 4, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 4, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 10, 'max_depth': 4, 'gamma': 1.5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 4, 'gamma': 0.5, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 3, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 0.5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 3, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 5, 'max_depth': 3, 'gamma': 0.5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 5, 'gamma': 0.5, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 10, 'max_depth': 3, 'gamma': 1, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 10, 'max_depth': 5, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 5, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 3, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 4, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 4, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 5, 'gamma': 2, 'colsample_bytree': 1.0}], 'split0_test_score': array([0.39314061, 0.42452487, 0.42328697, 0.4221219 , 0.41017986,\n       0.40930605, 0.42183063, 0.39619894, 0.42379669, 0.40879633,\n       0.40843224, 0.39219399, 0.4229957 , 0.4187723 , 0.41913639,\n       0.41098085, 0.40726717, 0.41025268, 0.40967014, 0.42408796,\n       0.40733998, 0.39517949, 0.41906357, 0.39496104, 0.39743683,\n       0.42372388, 0.42197626, 0.42292289, 0.40602927, 0.39539795,\n       0.40733998, 0.41986456, 0.42015583, 0.41840821, 0.41964611,\n       0.41942766, 0.39510668, 0.4116362 , 0.40814097, 0.42037428]), 'split1_test_score': array([0.40493701, 0.43515619, 0.43464647, 0.43202505, 0.41884512,\n       0.41811694, 0.43115124, 0.40384475, 0.43173378, 0.41826258,\n       0.420884  , 0.40595646, 0.43319013, 0.43275322, 0.43231632,\n       0.42168499, 0.41891793, 0.42066555, 0.42102964, 0.43406393,\n       0.41731595, 0.40326222, 0.43202505, 0.40602927, 0.40457293,\n       0.43362703, 0.43202505, 0.43369985, 0.41731595, 0.40304376,\n       0.41957329, 0.43085997, 0.43107842, 0.43260759, 0.43333576,\n       0.43304449, 0.40399039, 0.42204908, 0.42059273, 0.43275322]), 'split2_test_score': array([0.39962135, 0.43501056, 0.43399112, 0.4322435 , 0.42073837,\n       0.42008301, 0.42976771, 0.40166023, 0.43493774, 0.42153936,\n       0.4192092 , 0.3998398 , 0.43617564, 0.43027743, 0.43005898,\n       0.42350542, 0.42015583, 0.42153936, 0.42263162, 0.43595718,\n       0.42015583, 0.40238841, 0.43129688, 0.40027671, 0.40806816,\n       0.43522901, 0.43209787, 0.43573873, 0.42015583, 0.40202432,\n       0.41797131, 0.4322435 , 0.4301318 , 0.42998616, 0.43377266,\n       0.43071434, 0.3998398 , 0.4229957 , 0.42001019, 0.42867545]), 'split3_test_score': array([0.40037868, 0.43016312, 0.42768715, 0.42564812, 0.41545296,\n       0.41552578, 0.42674046, 0.39914069, 0.43023595, 0.41625401,\n       0.41450626, 0.40016021, 0.43089135, 0.42339062, 0.42288086,\n       0.41385086, 0.4110836 , 0.41523449, 0.42084183, 0.43038159,\n       0.41261288, 0.40023303, 0.42644917, 0.40074279, 0.40474803,\n       0.43103699, 0.42593941, 0.42958054, 0.41261288, 0.40023303,\n       0.41465191, 0.42433731, 0.42572094, 0.42535683, 0.42695893,\n       0.4239732 , 0.40074279, 0.41210312, 0.41443344, 0.42484707]), 'mean_test_score': array([0.39951941, 0.43121369, 0.42990293, 0.42800964, 0.41630408,\n       0.41575795, 0.42737251, 0.40021115, 0.43017604, 0.41621307,\n       0.41575793, 0.39953761, 0.4308132 , 0.42629839, 0.42609814,\n       0.41750553, 0.41435613, 0.41692302, 0.41854331, 0.43112267,\n       0.41435616, 0.40026579, 0.42720867, 0.40050245, 0.40370649,\n       0.43090423, 0.42800965, 0.4304855 , 0.41402848, 0.40017477,\n       0.41488412, 0.42682634, 0.42677175, 0.4265897 , 0.42842837,\n       0.42678992, 0.39991991, 0.41719603, 0.41579434, 0.42666251]), 'std_test_score': array([0.00420679, 0.00435326, 0.00468762, 0.00430962, 0.00401093,\n       0.00406054, 0.00357518, 0.00285248, 0.00405586, 0.0046792 ,\n       0.00483271, 0.004889  , 0.00488684, 0.00553613, 0.00531909,\n       0.0052296 , 0.00537144, 0.00454592, 0.00516992, 0.00452934,\n       0.00486473, 0.0031367 , 0.00516794, 0.00391669, 0.00387841,\n       0.00440717, 0.00428732, 0.00489746, 0.00534657, 0.0029357 ,\n       0.00470338, 0.00500693, 0.0043218 , 0.00538998, 0.00574307,\n       0.00540041, 0.00317882, 0.00533942, 0.00503051, 0.0045822 ]), 'rank_test_score': array([40,  1,  7, 10, 24, 27, 11, 36,  6, 25, 28, 39,  4, 18, 19, 21, 31,\n       23, 20,  2, 30, 35, 12, 34, 33,  3,  9,  5, 32, 37, 29, 13, 15, 17,\n        8, 14, 38, 22, 26, 16], dtype=int32)}\n\n Best estimator:\nXGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.8, eval_metric='merror',\n              gamma=1.5, gpu_id=0, importance_type='gain',\n              interaction_constraints='', learning_rate=0.02, max_delta_step=0,\n              max_depth=5, min_child_weight=1, missing=nan,\n              monotone_constraints='()', n_estimators=100, n_jobs=1, nthread=1,\n              num_class=9, num_parallel_tree=1, objective='multi:softprob',\n              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n              subsample=0.6, tree_method='gpu_hist', use_label_encoder=False,\n              validate_parameters=1, ...)\n\n Best normalized gini score for 4-fold search with 40 parameter combinations:\n-0.13757262931906233\n\n Best hyperparameters:\n{'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 0.8}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       42.112094      0.164324         0.204120        0.002349   \n",
       "1       85.002060      0.237468         0.332277        0.002272   \n",
       "2       85.937478      0.079971         0.333072        0.002427   \n",
       "3       65.824233      2.571792         0.345176        0.002609   \n",
       "4       54.270269      0.074487         0.250445        0.001539   \n",
       "5       45.033591      0.103009         0.252532        0.003553   \n",
       "6       64.507659      0.173469         0.343913        0.003199   \n",
       "7       33.457704      0.019562         0.200311        0.005941   \n",
       "8       65.460059      0.097824         0.327452        0.006695   \n",
       "9       44.229592      0.053008         0.251030        0.001390   \n",
       "10      49.793037      0.064088         0.254207        0.007460   \n",
       "11      36.732880      0.089937         0.201197        0.003270   \n",
       "12      63.830135      0.122255         0.323132        0.004150   \n",
       "13      86.496532      0.098891         0.326942        0.007251   \n",
       "14      86.561240      0.134789         0.319991        0.001925   \n",
       "15      48.978868      0.104734         0.255599        0.004319   \n",
       "16      55.031471      0.081730         0.256365        0.007946   \n",
       "17      54.208771      0.096533         0.252690        0.004807   \n",
       "18      47.922960      0.068807         0.255138        0.002032   \n",
       "19      73.692069      0.046553         0.325365        0.006536   \n",
       "20      55.020106      0.097317         0.250449        0.001927   \n",
       "21      31.248183      0.024666         0.196742        0.002843   \n",
       "22      76.313248      0.093241         0.321285        0.008522   \n",
       "23      31.766251      0.055885         0.202754        0.005291   \n",
       "24      30.436757      0.037159         0.199064        0.003847   \n",
       "25      73.277626      0.113293         0.329755        0.003794   \n",
       "26      76.181296      0.142210         0.322487        0.002648   \n",
       "27      63.621870      0.070962         0.332141        0.003192   \n",
       "28      54.931930      0.126077         0.253751        0.006161   \n",
       "29      31.191785      0.010033         0.200690        0.002264   \n",
       "30      49.787563      0.071626         0.252205        0.004932   \n",
       "31      76.094911      0.092324         0.324680        0.005761   \n",
       "32      75.862401      0.123177         0.328486        0.007051   \n",
       "33      83.794725      0.262050         0.340988        0.005838   \n",
       "34      84.851774      0.038400         0.328455        0.002132   \n",
       "35      86.400796      0.034205         0.323035        0.011209   \n",
       "36      31.760397      0.060540         0.200411        0.002769   \n",
       "37      48.985241      0.062044         0.254526        0.004265   \n",
       "38      49.743255      0.095744         0.251008        0.002485   \n",
       "39      86.049827      0.039327         0.323782        0.009319   \n",
       "\n",
       "   param_subsample param_min_child_weight param_max_depth param_gamma  \\\n",
       "0              1.0                      5               3           5   \n",
       "1              0.6                      1               5         1.5   \n",
       "2              0.8                      5               5           1   \n",
       "3              1.0                      5               5           5   \n",
       "4              0.8                      1               4           1   \n",
       "5              1.0                     10               4         1.5   \n",
       "6              1.0                      1               5           5   \n",
       "7              0.8                      1               3           2   \n",
       "8              0.8                      1               5         0.5   \n",
       "9              0.8                      1               4         1.5   \n",
       "10             1.0                      1               4         0.5   \n",
       "11             1.0                     10               3         1.5   \n",
       "12             0.6                     10               5           1   \n",
       "13             1.0                      5               5         0.5   \n",
       "14             1.0                      1               5         0.5   \n",
       "15             0.8                     10               4         1.5   \n",
       "16             1.0                     10               4           1   \n",
       "17             0.8                     10               4         1.5   \n",
       "18             0.6                      1               4         0.5   \n",
       "19             0.6                      1               5           2   \n",
       "20             1.0                      5               4           1   \n",
       "21             0.8                      1               3         1.5   \n",
       "22             1.0                      1               5         0.5   \n",
       "23             1.0                      5               3         1.5   \n",
       "24             0.6                      5               3         0.5   \n",
       "25             0.6                     10               5         1.5   \n",
       "26             1.0                     10               5         0.5   \n",
       "27             0.6                      5               5           2   \n",
       "28             1.0                      5               4         0.5   \n",
       "29             0.8                     10               3           1   \n",
       "30             1.0                      5               4           1   \n",
       "31             1.0                      5               5         1.5   \n",
       "32             1.0                     10               5         1.5   \n",
       "33             1.0                      5               5           5   \n",
       "34             0.8                     10               5           2   \n",
       "35             1.0                      5               5           1   \n",
       "36             1.0                      1               3         1.5   \n",
       "37             0.8                      1               4         1.5   \n",
       "38             1.0                      1               4         1.5   \n",
       "39             1.0                     10               5           2   \n",
       "\n",
       "   param_colsample_bytree                                             params  \\\n",
       "0                     1.0  {'subsample': 1.0, 'min_child_weight': 5, 'max...   \n",
       "1                     0.8  {'subsample': 0.6, 'min_child_weight': 1, 'max...   \n",
       "2                     0.8  {'subsample': 0.8, 'min_child_weight': 5, 'max...   \n",
       "3                     0.6  {'subsample': 1.0, 'min_child_weight': 5, 'max...   \n",
       "4                     1.0  {'subsample': 0.8, 'min_child_weight': 1, 'max...   \n",
       "5                     0.6  {'subsample': 1.0, 'min_child_weight': 10, 'ma...   \n",
       "6                     0.6  {'subsample': 1.0, 'min_child_weight': 1, 'max...   \n",
       "7                     0.8  {'subsample': 0.8, 'min_child_weight': 1, 'max...   \n",
       "8                     0.6  {'subsample': 0.8, 'min_child_weight': 1, 'max...   \n",
       "9                     0.6  {'subsample': 0.8, 'min_child_weight': 1, 'max...   \n",
       "10                    0.8  {'subsample': 1.0, 'min_child_weight': 1, 'max...   \n",
       "11                    1.0  {'subsample': 1.0, 'min_child_weight': 10, 'ma...   \n",
       "12                    0.6  {'subsample': 0.6, 'min_child_weight': 10, 'ma...   \n",
       "13                    1.0  {'subsample': 1.0, 'min_child_weight': 5, 'max...   \n",
       "14                    1.0  {'subsample': 1.0, 'min_child_weight': 1, 'max...   \n",
       "15                    0.8  {'subsample': 0.8, 'min_child_weight': 10, 'ma...   \n",
       "16                    1.0  {'subsample': 1.0, 'min_child_weight': 10, 'ma...   \n",
       "17                    1.0  {'subsample': 0.8, 'min_child_weight': 10, 'ma...   \n",
       "18                    0.8  {'subsample': 0.6, 'min_child_weight': 1, 'max...   \n",
       "19                    0.8  {'subsample': 0.6, 'min_child_weight': 1, 'max...   \n",
       "20                    1.0  {'subsample': 1.0, 'min_child_weight': 5, 'max...   \n",
       "21                    0.6  {'subsample': 0.8, 'min_child_weight': 1, 'max...   \n",
       "22                    0.8  {'subsample': 1.0, 'min_child_weight': 1, 'max...   \n",
       "23                    0.6  {'subsample': 1.0, 'min_child_weight': 5, 'max...   \n",
       "24                    0.6  {'subsample': 0.6, 'min_child_weight': 5, 'max...   \n",
       "25                    0.8  {'subsample': 0.6, 'min_child_weight': 10, 'ma...   \n",
       "26                    0.8  {'subsample': 1.0, 'min_child_weight': 10, 'ma...   \n",
       "27                    0.6  {'subsample': 0.6, 'min_child_weight': 5, 'max...   \n",
       "28                    1.0  {'subsample': 1.0, 'min_child_weight': 5, 'max...   \n",
       "29                    0.6  {'subsample': 0.8, 'min_child_weight': 10, 'ma...   \n",
       "30                    0.8  {'subsample': 1.0, 'min_child_weight': 5, 'max...   \n",
       "31                    0.8  {'subsample': 1.0, 'min_child_weight': 5, 'max...   \n",
       "32                    0.8  {'subsample': 1.0, 'min_child_weight': 10, 'ma...   \n",
       "33                    1.0  {'subsample': 1.0, 'min_child_weight': 5, 'max...   \n",
       "34                    1.0  {'subsample': 0.8, 'min_child_weight': 10, 'ma...   \n",
       "35                    1.0  {'subsample': 1.0, 'min_child_weight': 5, 'max...   \n",
       "36                    0.6  {'subsample': 1.0, 'min_child_weight': 1, 'max...   \n",
       "37                    0.8  {'subsample': 0.8, 'min_child_weight': 1, 'max...   \n",
       "38                    0.8  {'subsample': 1.0, 'min_child_weight': 1, 'max...   \n",
       "39                    1.0  {'subsample': 1.0, 'min_child_weight': 10, 'ma...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.393141           0.404937           0.399621   \n",
       "1            0.424525           0.435156           0.435011   \n",
       "2            0.423287           0.434646           0.433991   \n",
       "3            0.422122           0.432025           0.432244   \n",
       "4            0.410180           0.418845           0.420738   \n",
       "5            0.409306           0.418117           0.420083   \n",
       "6            0.421831           0.431151           0.429768   \n",
       "7            0.396199           0.403845           0.401660   \n",
       "8            0.423797           0.431734           0.434938   \n",
       "9            0.408796           0.418263           0.421539   \n",
       "10           0.408432           0.420884           0.419209   \n",
       "11           0.392194           0.405956           0.399840   \n",
       "12           0.422996           0.433190           0.436176   \n",
       "13           0.418772           0.432753           0.430277   \n",
       "14           0.419136           0.432316           0.430059   \n",
       "15           0.410981           0.421685           0.423505   \n",
       "16           0.407267           0.418918           0.420156   \n",
       "17           0.410253           0.420666           0.421539   \n",
       "18           0.409670           0.421030           0.422632   \n",
       "19           0.424088           0.434064           0.435957   \n",
       "20           0.407340           0.417316           0.420156   \n",
       "21           0.395179           0.403262           0.402388   \n",
       "22           0.419064           0.432025           0.431297   \n",
       "23           0.394961           0.406029           0.400277   \n",
       "24           0.397437           0.404573           0.408068   \n",
       "25           0.423724           0.433627           0.435229   \n",
       "26           0.421976           0.432025           0.432098   \n",
       "27           0.422923           0.433700           0.435739   \n",
       "28           0.406029           0.417316           0.420156   \n",
       "29           0.395398           0.403044           0.402024   \n",
       "30           0.407340           0.419573           0.417971   \n",
       "31           0.419865           0.430860           0.432244   \n",
       "32           0.420156           0.431078           0.430132   \n",
       "33           0.418408           0.432608           0.429986   \n",
       "34           0.419646           0.433336           0.433773   \n",
       "35           0.419428           0.433044           0.430714   \n",
       "36           0.395107           0.403990           0.399840   \n",
       "37           0.411636           0.422049           0.422996   \n",
       "38           0.408141           0.420593           0.420010   \n",
       "39           0.420374           0.432753           0.428675   \n",
       "\n",
       "    split3_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.400379         0.399519        0.004207               40  \n",
       "1            0.430163         0.431214        0.004353                1  \n",
       "2            0.427687         0.429903        0.004688                7  \n",
       "3            0.425648         0.428010        0.004310               10  \n",
       "4            0.415453         0.416304        0.004011               24  \n",
       "5            0.415526         0.415758        0.004061               27  \n",
       "6            0.426740         0.427373        0.003575               11  \n",
       "7            0.399141         0.400211        0.002852               36  \n",
       "8            0.430236         0.430176        0.004056                6  \n",
       "9            0.416254         0.416213        0.004679               25  \n",
       "10           0.414506         0.415758        0.004833               28  \n",
       "11           0.400160         0.399538        0.004889               39  \n",
       "12           0.430891         0.430813        0.004887                4  \n",
       "13           0.423391         0.426298        0.005536               18  \n",
       "14           0.422881         0.426098        0.005319               19  \n",
       "15           0.413851         0.417506        0.005230               21  \n",
       "16           0.411084         0.414356        0.005371               31  \n",
       "17           0.415234         0.416923        0.004546               23  \n",
       "18           0.420842         0.418543        0.005170               20  \n",
       "19           0.430382         0.431123        0.004529                2  \n",
       "20           0.412613         0.414356        0.004865               30  \n",
       "21           0.400233         0.400266        0.003137               35  \n",
       "22           0.426449         0.427209        0.005168               12  \n",
       "23           0.400743         0.400502        0.003917               34  \n",
       "24           0.404748         0.403706        0.003878               33  \n",
       "25           0.431037         0.430904        0.004407                3  \n",
       "26           0.425939         0.428010        0.004287                9  \n",
       "27           0.429581         0.430486        0.004897                5  \n",
       "28           0.412613         0.414028        0.005347               32  \n",
       "29           0.400233         0.400175        0.002936               37  \n",
       "30           0.414652         0.414884        0.004703               29  \n",
       "31           0.424337         0.426826        0.005007               13  \n",
       "32           0.425721         0.426772        0.004322               15  \n",
       "33           0.425357         0.426590        0.005390               17  \n",
       "34           0.426959         0.428428        0.005743                8  \n",
       "35           0.423973         0.426790        0.005400               14  \n",
       "36           0.400743         0.399920        0.003179               38  \n",
       "37           0.412103         0.417196        0.005339               22  \n",
       "38           0.414433         0.415794        0.005031               26  \n",
       "39           0.424847         0.426663        0.004582               16  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_subsample</th>\n      <th>param_min_child_weight</th>\n      <th>param_max_depth</th>\n      <th>param_gamma</th>\n      <th>param_colsample_bytree</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>42.112094</td>\n      <td>0.164324</td>\n      <td>0.204120</td>\n      <td>0.002349</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>3</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 5, 'max...</td>\n      <td>0.393141</td>\n      <td>0.404937</td>\n      <td>0.399621</td>\n      <td>0.400379</td>\n      <td>0.399519</td>\n      <td>0.004207</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>85.002060</td>\n      <td>0.237468</td>\n      <td>0.332277</td>\n      <td>0.002272</td>\n      <td>0.6</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1.5</td>\n      <td>0.8</td>\n      <td>{'subsample': 0.6, 'min_child_weight': 1, 'max...</td>\n      <td>0.424525</td>\n      <td>0.435156</td>\n      <td>0.435011</td>\n      <td>0.430163</td>\n      <td>0.431214</td>\n      <td>0.004353</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>85.937478</td>\n      <td>0.079971</td>\n      <td>0.333072</td>\n      <td>0.002427</td>\n      <td>0.8</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0.8</td>\n      <td>{'subsample': 0.8, 'min_child_weight': 5, 'max...</td>\n      <td>0.423287</td>\n      <td>0.434646</td>\n      <td>0.433991</td>\n      <td>0.427687</td>\n      <td>0.429903</td>\n      <td>0.004688</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>65.824233</td>\n      <td>2.571792</td>\n      <td>0.345176</td>\n      <td>0.002609</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>0.6</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 5, 'max...</td>\n      <td>0.422122</td>\n      <td>0.432025</td>\n      <td>0.432244</td>\n      <td>0.425648</td>\n      <td>0.428010</td>\n      <td>0.004310</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54.270269</td>\n      <td>0.074487</td>\n      <td>0.250445</td>\n      <td>0.001539</td>\n      <td>0.8</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>{'subsample': 0.8, 'min_child_weight': 1, 'max...</td>\n      <td>0.410180</td>\n      <td>0.418845</td>\n      <td>0.420738</td>\n      <td>0.415453</td>\n      <td>0.416304</td>\n      <td>0.004011</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>45.033591</td>\n      <td>0.103009</td>\n      <td>0.252532</td>\n      <td>0.003553</td>\n      <td>1.0</td>\n      <td>10</td>\n      <td>4</td>\n      <td>1.5</td>\n      <td>0.6</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 10, 'ma...</td>\n      <td>0.409306</td>\n      <td>0.418117</td>\n      <td>0.420083</td>\n      <td>0.415526</td>\n      <td>0.415758</td>\n      <td>0.004061</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>64.507659</td>\n      <td>0.173469</td>\n      <td>0.343913</td>\n      <td>0.003199</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>5</td>\n      <td>0.6</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 1, 'max...</td>\n      <td>0.421831</td>\n      <td>0.431151</td>\n      <td>0.429768</td>\n      <td>0.426740</td>\n      <td>0.427373</td>\n      <td>0.003575</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>33.457704</td>\n      <td>0.019562</td>\n      <td>0.200311</td>\n      <td>0.005941</td>\n      <td>0.8</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0.8</td>\n      <td>{'subsample': 0.8, 'min_child_weight': 1, 'max...</td>\n      <td>0.396199</td>\n      <td>0.403845</td>\n      <td>0.401660</td>\n      <td>0.399141</td>\n      <td>0.400211</td>\n      <td>0.002852</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>65.460059</td>\n      <td>0.097824</td>\n      <td>0.327452</td>\n      <td>0.006695</td>\n      <td>0.8</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0.5</td>\n      <td>0.6</td>\n      <td>{'subsample': 0.8, 'min_child_weight': 1, 'max...</td>\n      <td>0.423797</td>\n      <td>0.431734</td>\n      <td>0.434938</td>\n      <td>0.430236</td>\n      <td>0.430176</td>\n      <td>0.004056</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>44.229592</td>\n      <td>0.053008</td>\n      <td>0.251030</td>\n      <td>0.001390</td>\n      <td>0.8</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1.5</td>\n      <td>0.6</td>\n      <td>{'subsample': 0.8, 'min_child_weight': 1, 'max...</td>\n      <td>0.408796</td>\n      <td>0.418263</td>\n      <td>0.421539</td>\n      <td>0.416254</td>\n      <td>0.416213</td>\n      <td>0.004679</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>49.793037</td>\n      <td>0.064088</td>\n      <td>0.254207</td>\n      <td>0.007460</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0.5</td>\n      <td>0.8</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 1, 'max...</td>\n      <td>0.408432</td>\n      <td>0.420884</td>\n      <td>0.419209</td>\n      <td>0.414506</td>\n      <td>0.415758</td>\n      <td>0.004833</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>36.732880</td>\n      <td>0.089937</td>\n      <td>0.201197</td>\n      <td>0.003270</td>\n      <td>1.0</td>\n      <td>10</td>\n      <td>3</td>\n      <td>1.5</td>\n      <td>1.0</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 10, 'ma...</td>\n      <td>0.392194</td>\n      <td>0.405956</td>\n      <td>0.399840</td>\n      <td>0.400160</td>\n      <td>0.399538</td>\n      <td>0.004889</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>63.830135</td>\n      <td>0.122255</td>\n      <td>0.323132</td>\n      <td>0.004150</td>\n      <td>0.6</td>\n      <td>10</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0.6</td>\n      <td>{'subsample': 0.6, 'min_child_weight': 10, 'ma...</td>\n      <td>0.422996</td>\n      <td>0.433190</td>\n      <td>0.436176</td>\n      <td>0.430891</td>\n      <td>0.430813</td>\n      <td>0.004887</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>86.496532</td>\n      <td>0.098891</td>\n      <td>0.326942</td>\n      <td>0.007251</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 5, 'max...</td>\n      <td>0.418772</td>\n      <td>0.432753</td>\n      <td>0.430277</td>\n      <td>0.423391</td>\n      <td>0.426298</td>\n      <td>0.005536</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>86.561240</td>\n      <td>0.134789</td>\n      <td>0.319991</td>\n      <td>0.001925</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 1, 'max...</td>\n      <td>0.419136</td>\n      <td>0.432316</td>\n      <td>0.430059</td>\n      <td>0.422881</td>\n      <td>0.426098</td>\n      <td>0.005319</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>48.978868</td>\n      <td>0.104734</td>\n      <td>0.255599</td>\n      <td>0.004319</td>\n      <td>0.8</td>\n      <td>10</td>\n      <td>4</td>\n      <td>1.5</td>\n      <td>0.8</td>\n      <td>{'subsample': 0.8, 'min_child_weight': 10, 'ma...</td>\n      <td>0.410981</td>\n      <td>0.421685</td>\n      <td>0.423505</td>\n      <td>0.413851</td>\n      <td>0.417506</td>\n      <td>0.005230</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>55.031471</td>\n      <td>0.081730</td>\n      <td>0.256365</td>\n      <td>0.007946</td>\n      <td>1.0</td>\n      <td>10</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 10, 'ma...</td>\n      <td>0.407267</td>\n      <td>0.418918</td>\n      <td>0.420156</td>\n      <td>0.411084</td>\n      <td>0.414356</td>\n      <td>0.005371</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>54.208771</td>\n      <td>0.096533</td>\n      <td>0.252690</td>\n      <td>0.004807</td>\n      <td>0.8</td>\n      <td>10</td>\n      <td>4</td>\n      <td>1.5</td>\n      <td>1.0</td>\n      <td>{'subsample': 0.8, 'min_child_weight': 10, 'ma...</td>\n      <td>0.410253</td>\n      <td>0.420666</td>\n      <td>0.421539</td>\n      <td>0.415234</td>\n      <td>0.416923</td>\n      <td>0.004546</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>47.922960</td>\n      <td>0.068807</td>\n      <td>0.255138</td>\n      <td>0.002032</td>\n      <td>0.6</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0.5</td>\n      <td>0.8</td>\n      <td>{'subsample': 0.6, 'min_child_weight': 1, 'max...</td>\n      <td>0.409670</td>\n      <td>0.421030</td>\n      <td>0.422632</td>\n      <td>0.420842</td>\n      <td>0.418543</td>\n      <td>0.005170</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>73.692069</td>\n      <td>0.046553</td>\n      <td>0.325365</td>\n      <td>0.006536</td>\n      <td>0.6</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0.8</td>\n      <td>{'subsample': 0.6, 'min_child_weight': 1, 'max...</td>\n      <td>0.424088</td>\n      <td>0.434064</td>\n      <td>0.435957</td>\n      <td>0.430382</td>\n      <td>0.431123</td>\n      <td>0.004529</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>55.020106</td>\n      <td>0.097317</td>\n      <td>0.250449</td>\n      <td>0.001927</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 5, 'max...</td>\n      <td>0.407340</td>\n      <td>0.417316</td>\n      <td>0.420156</td>\n      <td>0.412613</td>\n      <td>0.414356</td>\n      <td>0.004865</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>31.248183</td>\n      <td>0.024666</td>\n      <td>0.196742</td>\n      <td>0.002843</td>\n      <td>0.8</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1.5</td>\n      <td>0.6</td>\n      <td>{'subsample': 0.8, 'min_child_weight': 1, 'max...</td>\n      <td>0.395179</td>\n      <td>0.403262</td>\n      <td>0.402388</td>\n      <td>0.400233</td>\n      <td>0.400266</td>\n      <td>0.003137</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>76.313248</td>\n      <td>0.093241</td>\n      <td>0.321285</td>\n      <td>0.008522</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0.5</td>\n      <td>0.8</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 1, 'max...</td>\n      <td>0.419064</td>\n      <td>0.432025</td>\n      <td>0.431297</td>\n      <td>0.426449</td>\n      <td>0.427209</td>\n      <td>0.005168</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>31.766251</td>\n      <td>0.055885</td>\n      <td>0.202754</td>\n      <td>0.005291</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>3</td>\n      <td>1.5</td>\n      <td>0.6</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 5, 'max...</td>\n      <td>0.394961</td>\n      <td>0.406029</td>\n      <td>0.400277</td>\n      <td>0.400743</td>\n      <td>0.400502</td>\n      <td>0.003917</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>30.436757</td>\n      <td>0.037159</td>\n      <td>0.199064</td>\n      <td>0.003847</td>\n      <td>0.6</td>\n      <td>5</td>\n      <td>3</td>\n      <td>0.5</td>\n      <td>0.6</td>\n      <td>{'subsample': 0.6, 'min_child_weight': 5, 'max...</td>\n      <td>0.397437</td>\n      <td>0.404573</td>\n      <td>0.408068</td>\n      <td>0.404748</td>\n      <td>0.403706</td>\n      <td>0.003878</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>73.277626</td>\n      <td>0.113293</td>\n      <td>0.329755</td>\n      <td>0.003794</td>\n      <td>0.6</td>\n      <td>10</td>\n      <td>5</td>\n      <td>1.5</td>\n      <td>0.8</td>\n      <td>{'subsample': 0.6, 'min_child_weight': 10, 'ma...</td>\n      <td>0.423724</td>\n      <td>0.433627</td>\n      <td>0.435229</td>\n      <td>0.431037</td>\n      <td>0.430904</td>\n      <td>0.004407</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>76.181296</td>\n      <td>0.142210</td>\n      <td>0.322487</td>\n      <td>0.002648</td>\n      <td>1.0</td>\n      <td>10</td>\n      <td>5</td>\n      <td>0.5</td>\n      <td>0.8</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 10, 'ma...</td>\n      <td>0.421976</td>\n      <td>0.432025</td>\n      <td>0.432098</td>\n      <td>0.425939</td>\n      <td>0.428010</td>\n      <td>0.004287</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>63.621870</td>\n      <td>0.070962</td>\n      <td>0.332141</td>\n      <td>0.003192</td>\n      <td>0.6</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0.6</td>\n      <td>{'subsample': 0.6, 'min_child_weight': 5, 'max...</td>\n      <td>0.422923</td>\n      <td>0.433700</td>\n      <td>0.435739</td>\n      <td>0.429581</td>\n      <td>0.430486</td>\n      <td>0.004897</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>54.931930</td>\n      <td>0.126077</td>\n      <td>0.253751</td>\n      <td>0.006161</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>4</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 5, 'max...</td>\n      <td>0.406029</td>\n      <td>0.417316</td>\n      <td>0.420156</td>\n      <td>0.412613</td>\n      <td>0.414028</td>\n      <td>0.005347</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>31.191785</td>\n      <td>0.010033</td>\n      <td>0.200690</td>\n      <td>0.002264</td>\n      <td>0.8</td>\n      <td>10</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.6</td>\n      <td>{'subsample': 0.8, 'min_child_weight': 10, 'ma...</td>\n      <td>0.395398</td>\n      <td>0.403044</td>\n      <td>0.402024</td>\n      <td>0.400233</td>\n      <td>0.400175</td>\n      <td>0.002936</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>49.787563</td>\n      <td>0.071626</td>\n      <td>0.252205</td>\n      <td>0.004932</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0.8</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 5, 'max...</td>\n      <td>0.407340</td>\n      <td>0.419573</td>\n      <td>0.417971</td>\n      <td>0.414652</td>\n      <td>0.414884</td>\n      <td>0.004703</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>76.094911</td>\n      <td>0.092324</td>\n      <td>0.324680</td>\n      <td>0.005761</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1.5</td>\n      <td>0.8</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 5, 'max...</td>\n      <td>0.419865</td>\n      <td>0.430860</td>\n      <td>0.432244</td>\n      <td>0.424337</td>\n      <td>0.426826</td>\n      <td>0.005007</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>75.862401</td>\n      <td>0.123177</td>\n      <td>0.328486</td>\n      <td>0.007051</td>\n      <td>1.0</td>\n      <td>10</td>\n      <td>5</td>\n      <td>1.5</td>\n      <td>0.8</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 10, 'ma...</td>\n      <td>0.420156</td>\n      <td>0.431078</td>\n      <td>0.430132</td>\n      <td>0.425721</td>\n      <td>0.426772</td>\n      <td>0.004322</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>83.794725</td>\n      <td>0.262050</td>\n      <td>0.340988</td>\n      <td>0.005838</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 5, 'max...</td>\n      <td>0.418408</td>\n      <td>0.432608</td>\n      <td>0.429986</td>\n      <td>0.425357</td>\n      <td>0.426590</td>\n      <td>0.005390</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>84.851774</td>\n      <td>0.038400</td>\n      <td>0.328455</td>\n      <td>0.002132</td>\n      <td>0.8</td>\n      <td>10</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>{'subsample': 0.8, 'min_child_weight': 10, 'ma...</td>\n      <td>0.419646</td>\n      <td>0.433336</td>\n      <td>0.433773</td>\n      <td>0.426959</td>\n      <td>0.428428</td>\n      <td>0.005743</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>86.400796</td>\n      <td>0.034205</td>\n      <td>0.323035</td>\n      <td>0.011209</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 5, 'max...</td>\n      <td>0.419428</td>\n      <td>0.433044</td>\n      <td>0.430714</td>\n      <td>0.423973</td>\n      <td>0.426790</td>\n      <td>0.005400</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>31.760397</td>\n      <td>0.060540</td>\n      <td>0.200411</td>\n      <td>0.002769</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1.5</td>\n      <td>0.6</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 1, 'max...</td>\n      <td>0.395107</td>\n      <td>0.403990</td>\n      <td>0.399840</td>\n      <td>0.400743</td>\n      <td>0.399920</td>\n      <td>0.003179</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>48.985241</td>\n      <td>0.062044</td>\n      <td>0.254526</td>\n      <td>0.004265</td>\n      <td>0.8</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1.5</td>\n      <td>0.8</td>\n      <td>{'subsample': 0.8, 'min_child_weight': 1, 'max...</td>\n      <td>0.411636</td>\n      <td>0.422049</td>\n      <td>0.422996</td>\n      <td>0.412103</td>\n      <td>0.417196</td>\n      <td>0.005339</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>49.743255</td>\n      <td>0.095744</td>\n      <td>0.251008</td>\n      <td>0.002485</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1.5</td>\n      <td>0.8</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 1, 'max...</td>\n      <td>0.408141</td>\n      <td>0.420593</td>\n      <td>0.420010</td>\n      <td>0.414433</td>\n      <td>0.415794</td>\n      <td>0.005031</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>86.049827</td>\n      <td>0.039327</td>\n      <td>0.323782</td>\n      <td>0.009319</td>\n      <td>1.0</td>\n      <td>10</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>{'subsample': 1.0, 'min_child_weight': 10, 'ma...</td>\n      <td>0.420374</td>\n      <td>0.432753</td>\n      <td>0.428675</td>\n      <td>0.424847</td>\n      <td>0.426663</td>\n      <td>0.004582</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 150
    }
   ],
   "source": [
    "# print('\\n All results:')\n",
    "# print(random_search.cv_results_)\n",
    "# print('\\n Best estimator:')\n",
    "# print(random_search.best_estimator_)\n",
    "# print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "# print(random_search.best_score_ * 2 - 1)\n",
    "# print('\\n Best hyperparameters:')\n",
    "# print(random_search.best_params_)\n",
    "# results = pd.DataFrame(random_search.cv_results_)\n",
    "# results\n",
    "# #results.to_csv('xgb-random-grid-search-results-01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, accuracy_score\n",
    "# y_pred = xgb.predict(X_test)\n",
    "# print(accuracy_score(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}